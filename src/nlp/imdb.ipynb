{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "### Define global constants\n",
    "SEED = 42\n",
    "\n",
    "### Getting data, modeling & separating into train/test data\n",
    "df = pd.read_csv('data/imdb-reviews-pt-br.csv')\n",
    "\n",
    "classification_column = df['sentiment'].replace(['neg', 'pos'], [0, 1])\n",
    "df['classification'] = classification_column\n",
    "\n",
    "### Define util global vars\n",
    "all_words = ' '.join([text for text in df['text_pt']])\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "whitespace_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "punct_tokenizer = nltk.tokenize.WordPunctTokenizer() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict_text(text_df, x_column, y_column):\n",
    "  vectorize = CountVectorizer(lowercase=False, max_features=50)\n",
    "  bag_of_words = vectorize.fit_transform(text_df[x_column])\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    text_df[y_column],\n",
    "    random_state=SEED\n",
    "  )\n",
    "\n",
    "  ### Predict with LogisticRegression\n",
    "  logistic_regression_model = LogisticRegression()\n",
    "  logistic_regression_model.fit(x_train, y_train)\n",
    "  logistic_regression_accuracy = logistic_regression_model.score(x_test, y_test)\n",
    "\n",
    "  print(logistic_regression_accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_text(df, 'text_pt', 'classification')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Create a wordcloud\n",
    "def get_words_wordcloud(text_df, x_column, y_column, y_value):\n",
    "  all_words_based_on_y = text_df.query(f'{y_column} == \"{y_value}\"')\n",
    "  all_words_based_on_y = ' '.join([text for text in all_words_based_on_y[x_column]])\n",
    "\n",
    "  wordcloud = WordCloud(\n",
    "    width=800, \n",
    "    height=500, \n",
    "    max_font_size=110,\n",
    "    collocations=False\n",
    "  ).generate(all_words_based_on_y)\n",
    "\n",
    "  plt.figure(figsize=(10, 7))\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_words_wordcloud(df, 'text_pt', 'sentiment', 'pos')\n",
    "get_words_wordcloud(df, 'text_pt', 'sentiment', 'neg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Tokenize white-spaces, getting words frequency & plot most frequent data\n",
    "def tokenize_and_plot_most_frequent_data(text_df, x_column, quantity):\n",
    "  all_words_from_x_column = ' '.join([text for text in text_df[x_column]])\n",
    "\n",
    "  tokenized_phrases = whitespace_tokenizer.tokenize(all_words_from_x_column)\n",
    "  words_frequency = nltk.FreqDist(tokenized_phrases)\n",
    "\n",
    "  words_frequency_df = pd.DataFrame({ \n",
    "    'Word': list(words_frequency.keys()), \n",
    "    'Frequency': list(words_frequency.values()) \n",
    "  })\n",
    "\n",
    "  n_most_frequent_words = words_frequency_df.nlargest(columns='Frequency', n=quantity)\n",
    "\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  ax = sns.barplot(data=n_most_frequent_words, x='Word', y='Frequency', color='gray')\n",
    "  ax.set(ylabel='Count')\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenize_and_plot_most_frequent_data(df, 'text_pt', 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "### Removes stopwords in all phrases from DataFrame\n",
    "all_phrases_without_stopwords = []\n",
    "\n",
    "for opinion in df['text_pt']:\n",
    "  phrase_words = whitespace_tokenizer.tokenize(opinion)\n",
    "  phrase_without_stopwords = []\n",
    "\n",
    "  for word in phrase_words:\n",
    "    if word not in stopwords:\n",
    "      phrase_without_stopwords.append(word)\n",
    "\n",
    "  all_phrases_without_stopwords.append(' '.join(phrase_without_stopwords))\n",
    "\n",
    "df['filter_01'] = all_phrases_without_stopwords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_text(df, 'filter_01', 'classification')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenize_and_plot_most_frequent_data(df, 'filter_01', 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "### Removes punctuation in all phrases from DataFrame\n",
    "punctuation_list = [punct for punct in punctuation]\n",
    "punctuation_and_stopwords = punctuation_list + stopwords\n",
    "\n",
    "all_words_without_punctuation = []\n",
    "\n",
    "for opinion in df['filter_01']:\n",
    "  phrase_words = punct_tokenizer.tokenize(opinion)\n",
    "  phrase_without_puncts = []\n",
    "\n",
    "  for word in phrase_words:\n",
    "    if word not in punctuation_and_stopwords:\n",
    "      phrase_without_puncts.append(word)\n",
    "\n",
    "  all_words_without_punctuation.append(' '.join(phrase_without_puncts))\n",
    "\n",
    "df['filter_02'] = all_words_without_punctuation"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg   \n",
       "\n",
       "   classification                                          filter_01  \\\n",
       "0               0  Mais vez, Sr. Costner arrumou filme tempo nece...   \n",
       "1               0  Este exemplo motivo maioria filmes ação mesmos...   \n",
       "2               0  Primeiro tudo odeio raps imbecis, poderiam agi...   \n",
       "3               0  Nem Beatles puderam escrever músicas todos gos...   \n",
       "4               0  Filmes fotos latão palavra apropriada eles, ve...   \n",
       "\n",
       "                                           filter_02  \n",
       "0  Mais vez Sr Costner arrumou filme tempo necess...  \n",
       "1  Este exemplo motivo maioria filmes ação mesmos...  \n",
       "2  Primeiro tudo odeio raps imbecis poderiam agir...  \n",
       "3  Nem Beatles puderam escrever músicas todos gos...  \n",
       "4  Filmes fotos latão palavra apropriada verdade ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>classification</th>\n",
       "      <th>filter_01</th>\n",
       "      <th>filter_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mais vez, Sr. Costner arrumou filme tempo nece...</td>\n",
       "      <td>Mais vez Sr Costner arrumou filme tempo necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Este exemplo motivo maioria filmes ação mesmos...</td>\n",
       "      <td>Este exemplo motivo maioria filmes ação mesmos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Primeiro tudo odeio raps imbecis, poderiam agi...</td>\n",
       "      <td>Primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Nem Beatles puderam escrever músicas todos gos...</td>\n",
       "      <td>Nem Beatles puderam escrever músicas todos gos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Filmes fotos latão palavra apropriada eles, ve...</td>\n",
       "      <td>Filmes fotos latão palavra apropriada verdade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('behind_classification-EIFFRDf1': pipenv)"
  },
  "interpreter": {
   "hash": "5236c5d3e2e84c3c74c4f493e8c79fed12c86e43bb827fd0058b228c568a6eb0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}