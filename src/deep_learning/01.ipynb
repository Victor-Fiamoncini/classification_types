{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "### Load dataset & train/test data\n",
    "dataset = keras.datasets.fashion_mnist\n",
    "((x_train, y_train), (x_test, y_test)) = dataset.load_data()\n",
    "\n",
    "### Define constants\n",
    "all_classifications_indexes = y_train.max()\n",
    "all_classification_names = [\n",
    "  'T-shirt/top',\n",
    "  'Trouser',\n",
    "  'Pullover',\n",
    "  'Dress',\n",
    "  'Coat',\n",
    "  'Sandal',\n",
    "  'Shirt',\n",
    "  'Sneaker',\n",
    "  'Bag',\n",
    "  'Ankle boot',\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Plotting first 10 images\n",
    "for image in range(10):\n",
    "  plt.subplot(2, 5, image + 1)\n",
    "  plt.imshow(x_train[image])\n",
    "  plt.title(all_classification_names[y_train[image]])\n",
    "\n",
    "### Getting color range of images\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "\n",
    "### Tranforms/Normalize image color range (0...255) to floats (0...1)\n",
    "x_train = x_train/float(255)\n",
    "x_test = x_test/float(255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Create model with some layers\n",
    "# Entry-layer: flatten one image with 28px into an unidimensional array\n",
    "# Intermediary-layer: relu - classify based all inputs (Xs non negatives) based on pre-determinated Ys\n",
    "# Intermediary-layer: dropout normalize - sleepy 20% of unities\n",
    "# Intermediary-layer: softmax - adds a percentage value in all inputs to determine them, based on 10 classifications we have\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  keras.layers.Dense(256, activation=tensorflow.nn.relu),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Dense(10, activation=tensorflow.nn.softmax),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam', \n",
    "  loss='sparse_categorical_crossentropy', \n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Model summary\n",
    "summary = model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "layer_dense_weights = model.layers[1].get_weights()\n",
    "layer_dense_weights"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[-0.03803247,  0.01487277, -0.09337955, ..., -0.05664299,\n",
       "         -0.02154523,  0.12139954],\n",
       "        [-0.16731296, -0.0397872 , -0.10210093, ...,  0.04101872,\n",
       "          0.07368104,  0.06293272],\n",
       "        [-0.07250023, -0.03388084,  0.04521769, ..., -0.06839756,\n",
       "          0.17466547,  0.16791338],\n",
       "        ...,\n",
       "        [-0.04703135,  0.20638038, -0.02243831, ...,  0.08739859,\n",
       "          0.12178449, -0.12116287],\n",
       "        [-0.02930786,  0.2213131 , -0.16724719, ...,  0.0650958 ,\n",
       "          0.12525241, -0.02324382],\n",
       "        [-0.03905143, -0.04642093, -0.04665668, ...,  0.13229264,\n",
       "         -0.01617111,  0.09592956]], dtype=float32),\n",
       " array([ 2.83957362e-01,  9.03308168e-02,  1.27305776e-01,  9.88270715e-02,\n",
       "         1.00522019e-01, -9.55169182e-03,  1.26606718e-01,  2.61395395e-01,\n",
       "         2.00518623e-01, -2.53193945e-01,  3.49803060e-01,  3.28710139e-01,\n",
       "         3.18171978e-01,  2.91327536e-01,  1.90622315e-01,  2.08812691e-02,\n",
       "        -2.65013147e-02,  1.49336368e-01, -2.02176422e-01,  3.00269663e-01,\n",
       "         2.61422426e-01,  2.11074471e-01,  3.14843744e-01,  2.78774917e-01,\n",
       "         3.05258632e-01,  2.87576020e-01,  2.90212594e-02,  1.41162559e-01,\n",
       "         3.19310844e-01,  1.98996976e-01,  3.78272623e-01, -8.86121765e-03,\n",
       "         2.53711283e-01,  1.29376695e-01,  1.13802828e-01, -8.61172657e-03,\n",
       "         1.20402686e-01,  4.90215272e-02,  2.35459179e-01,  6.14919141e-02,\n",
       "         2.20838144e-01, -2.79677838e-01, -5.47727123e-02,  1.50564119e-01,\n",
       "         2.91572690e-01, -7.11897947e-03,  1.85362205e-01,  2.42591724e-01,\n",
       "        -3.30733120e-01,  4.96569499e-02,  1.40030235e-01,  3.99224073e-01,\n",
       "         1.08907945e-01, -2.27588788e-01,  1.19674817e-01,  1.79971546e-01,\n",
       "         2.70568788e-01,  3.75182658e-01, -3.61932181e-02,  4.80723381e-01,\n",
       "        -1.24483304e-02,  3.62852104e-02,  3.05938482e-01,  9.24459565e-03,\n",
       "         1.82888433e-01, -5.24072386e-02, -3.22923101e-02,  3.57520610e-01,\n",
       "         3.25555876e-02,  3.19257081e-01, -8.58038142e-02,  4.92962152e-02,\n",
       "         3.37373495e-01,  1.95778295e-01,  1.01559823e-02,  2.72854805e-01,\n",
       "         6.07830286e-02, -2.74409447e-02,  9.74303707e-02,  8.94900188e-02,\n",
       "         1.97339579e-01,  1.45082518e-01, -2.49450896e-02,  1.40695170e-01,\n",
       "        -1.35036230e-01, -8.11314210e-02,  4.58613597e-03, -1.48218602e-01,\n",
       "         2.83517152e-01,  9.68714878e-02,  1.86629385e-01,  3.00440937e-01,\n",
       "         2.01879770e-01,  1.26935905e-02,  1.80377454e-01,  3.87051888e-02,\n",
       "         5.00854552e-02,  9.83882993e-02, -1.27257392e-01,  3.22032064e-01,\n",
       "         1.50301099e-01,  1.45753259e-02, -1.22622520e-01,  2.56073207e-01,\n",
       "         1.40024245e-01,  1.48918550e-03, -4.01452184e-02, -7.98810571e-02,\n",
       "         4.13108133e-02,  1.86740354e-01, -9.81767848e-02, -1.77006483e-01,\n",
       "        -5.94900660e-02, -1.17796194e-02,  2.77797908e-01,  7.76695907e-02,\n",
       "        -5.91089390e-02,  4.39553671e-02,  1.45684138e-01, -7.60060325e-02,\n",
       "        -2.61229500e-02, -3.38427685e-02,  3.29466730e-01,  5.12968898e-02,\n",
       "        -2.65331343e-02,  1.72732443e-01,  1.45164058e-01,  3.13974112e-01,\n",
       "        -1.78749472e-01,  3.38857114e-01,  1.53857052e-01, -2.10407749e-02,\n",
       "         2.88633406e-01,  2.44538769e-01,  1.16266444e-01, -1.99080482e-02,\n",
       "         2.22669944e-01,  2.91347690e-02,  1.69734091e-01, -8.68866034e-03,\n",
       "         3.99858683e-01, -2.49538124e-01, -3.51396215e-04,  1.24592058e-01,\n",
       "        -5.52123822e-02, -1.51421756e-01,  9.63514596e-02, -1.32116541e-01,\n",
       "        -9.81278792e-02,  1.15181394e-01,  1.26153752e-01,  8.55694488e-02,\n",
       "         3.19745421e-01,  5.08550331e-02,  2.04928443e-01, -5.81427105e-02,\n",
       "         2.75723875e-01,  1.36726186e-01,  1.48874652e-02,  2.76751757e-01,\n",
       "         7.76606277e-02, -2.89779395e-01, -1.58131287e-01,  1.10804766e-01,\n",
       "         1.78719088e-01,  2.88893193e-01,  8.46380517e-02,  1.86916128e-01,\n",
       "        -7.37214684e-02,  1.02360928e-02,  2.35110179e-01,  2.74811924e-01,\n",
       "         1.37711495e-01, -3.63082647e-01,  3.02474022e-01, -6.78650737e-02,\n",
       "         2.58982778e-01,  1.88640580e-01,  2.84705311e-01,  1.57832369e-01,\n",
       "         3.52277964e-01,  7.28865862e-02,  2.47303739e-01, -5.28982608e-03,\n",
       "         1.29516676e-01,  2.66705275e-01, -9.25358906e-02,  9.73625779e-02,\n",
       "         1.53073251e-01,  1.76358759e-01,  1.83366731e-01, -6.75954744e-02,\n",
       "         3.93208042e-02,  9.54181775e-02,  3.55105489e-01,  1.49661629e-02,\n",
       "         2.58385420e-01,  3.06477323e-02,  1.36257410e-02,  8.63147527e-02,\n",
       "         3.33952725e-01,  3.39915782e-01,  3.12694401e-01, -9.57885832e-02,\n",
       "         3.53233516e-01, -1.55884817e-01, -2.28856504e-01,  2.52834350e-01,\n",
       "         2.74756193e-01,  3.74892354e-01,  5.27381539e-01,  4.35702242e-02,\n",
       "         2.47151464e-01,  3.43010783e-01, -1.07967947e-02, -1.26639113e-01,\n",
       "        -1.24269016e-01,  2.95368314e-01, -1.48047626e-01, -6.51958138e-02,\n",
       "        -2.13815793e-02,  3.57163161e-01,  2.88558930e-01,  4.52955253e-02,\n",
       "         4.89616953e-02,  2.80316710e-01, -2.36320999e-02, -1.52402088e-01,\n",
       "         2.07169592e-01, -3.09118360e-01,  3.36222142e-01, -3.76760699e-02,\n",
       "         1.91561624e-01, -9.95845906e-03,  3.54985297e-02,  1.71124414e-01,\n",
       "        -2.12620005e-01,  1.25625087e-02,  1.26697153e-01,  1.87896974e-02,\n",
       "         1.69083893e-01, -6.58246428e-02, -2.12511197e-01,  1.37204513e-01,\n",
       "         1.21303737e-01,  2.02901229e-01,  2.23485082e-02, -2.02330470e-01,\n",
       "         2.26316705e-01,  9.94015634e-02,  2.51028389e-01,  1.86201885e-01,\n",
       "         2.80168921e-01, -4.79072332e-02, -4.70042825e-02, -6.13063127e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Save model\n",
    "model.save('model.h5')\n",
    "saved_model = keras.models.load_model('model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Test & validate model\n",
    "predictions = model.predict(x_test)\n",
    "loss_test, accuracy_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Loss:', loss_test)\n",
    "print('Accuracy:', accuracy_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Plot loss by epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss by epoch')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Plot accuracy by epoch\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy by epoch')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "286eef7d23a33eccd745f2f2ceb7e69b184b09986d2f8b137404410aecee58e1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}